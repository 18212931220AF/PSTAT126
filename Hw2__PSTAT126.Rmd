---
title: "Homework 2"
subtitle: "PSTAT Winter 2023"
author: "Yanru Fang"
output: pdf_document
date: "February 17th, 2023 at 23:59 PT"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

1. This question uses the *cereal* data set available in the Homework Assignment 2 on Canvas. The following command can be used to read the data into R. Make sure the "cereal.txt" file is in the same folder as your R/Rmd file.


```{r cereal}
Cereal <- read.table("cereal.txt",header=T)
str(Cereal)
```

```{r cereal2, include=F}
model <- lm(rating~protein+fat+fiber+carbo+sugars+potass+vitamins+cups, data= Cereal)
summary(model)
```
The data set *cereal* contains measurements for a set of $77$ cereal brands. For this assignment only consider the following variables:

- Rating: Quality rating
- Protein: Amount of protein. 
- Fat: Amount of fat.
- Fiber: Amount of fiber.
- Carbo: Amount of carbohydrates.
- Sugars: Amount of sugar.
- Potass: Amount of potassium. 
- Vitamins: Amount of vitamins.
- Cups: Portion size in cups.

Our goal is to study how *rating* is related to all other 8 variables.\
\
(a) (4pts) Explore the data and perform a descriptive analysis of each variable, include any plot/statistics that you find relevant (histograms, scatter diagrams, correlation coefficients). Did you find any outlier? If yes, is it reasonable to remove this observation? why?\
\
```{r echo=TRUE}
new_cereal <- Cereal[,-c(1,2,3,4,7,13,14)]
summary(new_cereal)
```

```{r echo=TRUE}
boxplot(new_cereal, col = 'yellow')
```
```{r}
boxplot(new_cereal$potass, main = "Potass", col = "blue")
boxplot(new_cereal$fiber, main = "Fiber", col = "blue")
boxplot(new_cereal$carbo, main = "Carbo", col = 'blue')
boxplot(new_cereal$vitamins, main = "Vitamins", col = 'blue')
```

From these boxplot we can see that there are some outlier in Potass, Fiber, Carbo and Vitamins. Potass have four outlier, Fiber have three outlier, Carbo have one and Vitamins have two outlier. I think some of outlier can still keep. However, we can there are three negative numbers in Carbo, Sugars and Potass from the summary output. Those negative number should be removed.

```{r echo=TRUE}
cor(new_cereal, new_cereal$rating)
```
The correlation between these variables and rating are shown in this table. The Protein, Fat, Fiber, Carbo, Sugars, Potass, Vitamins, Cups respectively are 0.467, -0.405, 0.603, 0.056, -0.756, 0.416, -0.214 and -0.223. 
```{r echo=TRUE}
new_cereal <- new_cereal[-c(which(new_cereal$carbo<0), which(new_cereal$sugars<0), 
                            which(new_cereal$potass<0)),]
```

(b) (3pts) Use the lm function in R to fit the MLR model with *rating* as the response and the other $8$ variables as predictors. Display the summary output.\
\
```{r echo=TRUE}
mod <- lm(formula = rating ~ protein + fat + fiber + carbo + sugars + potass + vitamins + 
          cups, data = new_cereal)
summary(mod)
```


(c)(3pts) Which predictor variables are statistically significant under the significance threshold value of 0.01?\
\
Through the data we can know that the Protein, Fat, Fiber, Sugars and Vitamins are statistically significant under the significance threshold value of 0.01.


(d)(2pts) What proportion of the total variation in the response is explained by the predictors?
```{r echo=TRUE}
summary(mod)$adj.r.squared
```
Therefore, the model explains 90.38% of the total variation in the response.


(e)(3pts) What is the null hypothesis of the global F-test? What is the p-value for the global F-test? Do the 7 predictor variables explain a significant proportion of the variation in the response?\
\
$H_0$: $\beta_{protein}=\beta_{fat}=\beta_{fiber}=\beta_{carbo}=\beta_{sugars}=\beta_{potass}=\beta_{vitamins}=\beta_{cups}=0$\
\
$H_1$: $\beta_j\not=0$ for at least one $j\in$ {protein, fat, fiber, carbo, sugars, potass, vitamins, cups}
```{r echo=TRUE}
mod_M <- lm(formula = rating ~ protein + fat + fiber + carbo + sugars + potass + vitamins 
            + cups, data = new_cereal)
mod_m <- lm(formula = rating ~ 1, data = new_cereal)
anova(mod_m, mod_M)
```
From the table that showed, we can see that the p-value is 2.2e-16, which is really small and smaller than 0.01. Therefore, we can reject the null hypothesis, which is $H_0$. We can conclude that there are at least one of the predictors variables explain a significant proportion of the variation in the response.\
\

(f)(2pts) Consider testing the null hypothesis $H_0: \beta_{carbo} = 0$, where $\beta_{carbo}$ is the coefficient corresponding to *carbohydrates* in the MLR model. Use the t value available in the summary output to compute the p-value associated with this test, and verify that the p-value you get is identical to the p-value provided in the summary output.
```{r echo=TRUE}
pvalue_carbo <- 2*pt(-2.08, 65)
pvalue_carbo
```
The p-value I get from the function is 0.0415, and the p-value from the summary output is 0.0418. These two number is almost same.\
\

(g)(4pts)Suppose we are interested in knowing if either *vitamins* or *potass* had any relation to the response *rating*. What would be the corresponding null hypothesis of this statistical test? Construct a F-test, report the corresponding p-value, and your conclusion.\
\
$H_0$: $\beta_{vitamins} = \beta_{potass}=0$\
\
$H_1$: $\beta_{vitamins}\not=0$ or $\beta_{potass}\not=0$
```{r echo=TRUE}
mod2_M <- lm(formula = rating ~ protein + fat + fiber + carbo + sugars + potass + vitamins 
             + cups, data = new_cereal)
mod2_m <- lm(formula = rating ~ protein + fat + fiber + carbo + sugars + cups, 
             data = new_cereal)
anova(mod2_m, mod2_M)
```
From the table that given, we can see that the p-value is 0.001785, which is really small and smaller than 0.01. Therefore, we can reject the null hypothesis. We can conclude that vitamins or potass had relation to the response rating. Hence, we should use larger model(mod2_M) instead of smaller model(mod2_m).\
\

(h)(3pts) Use the summary output to construct a 99% confidence interval for $\beta_{protein}$. What is the interpretation of this confidence interval?
```{r echo=TRUE}
CI.beta_protein <- c(summary(mod)$coefficients[2,1]-qt(0.995,mod$df.residual)
                     *summary(mod)$coefficients[2,2],
                     summary(mod)$coefficients[2,1]+qt(0.995,mod$df.residual)
                     *summary(mod)$coefficients[2,2])
CI.beta_protein
```
Confidence interval for $\beta_{protein}$ is between 0.5471 and 3.9852. This means that we are 99% confident that the true value is contain in this confidence interval.\
\

(i)(3pts) What is the predicted *rating* for a cereal brand with the following information:\

- Protein=3 
- Fat=5
- Fiber=2
- Carbo=13
- Sugars=6
- Potass=60 
- Vitamins=25
- Cups=0.8
```{r echo=TRUE}
predict(mod, newdata = data.frame(protein=3, fat=5, fiber=2, carbo=13, sugars=6, 
                                  potass=60, vitamins=25, cups=0.8))
```
The predicted rating for a cereal brand is 30.244.\
\

(j). (3pts) What is the 95\% prediction interval for the observation in part (i)? What is the interpretation of this prediction interval?\
```{r echo=TRUE}
predict(mod, newdata = data.frame(protein=3, fat=5, fiber=2, carbo=13, sugars=6, 
                                  potass=60, vitamins=25, cups=0.8), interval = 'predict')
```
The 95% prediction interval is $[19.962, 40.525]$, which means that we have 95% confident that the value of rating for Cereal will fall between 19.962 and 40.525.\
\

Q2.(20pts) Consider the MLR model with $p$ predictors:
$$\mathbf{y}=\mathbf{X}\boldsymbol \beta+\boldsymbol\epsilon, \qquad \boldsymbol \epsilon \sim N_n(\boldsymbol 0,\sigma^2\boldsymbol I_n)$$
If we define $\hat\sigma^2=\frac{SSR}{n-p^*}$, with $p^*=p+1$. Use theoretical results from the lectures to show that $\hat\sigma^2$ is an unbiased estimator of $\sigma^2$. Find $V(\hat\sigma^2)$.

If we want to show $\hat\sigma^2$ is an unbiased estimator of $\sigma^2$, we need to show the expected value is equal to $\sigma^2$.
$$
\begin{split}
E(\hat{\sigma}^2)&=E(\frac{SSR}{n-p-1})\\
&=\frac{1}{n-p-1} E(SSR)\\
&=\frac{1}{n-p-1} E(\sum_{i=1}^{n} (y_i-\hat{y_i})^2) \\
&=\frac{1}{n-p-1} E(\sum_{i=1}^{n} \epsilon_i^2)\\
\end{split}
$$
Through this formula, we need to know the value of $E(\sum_{i=1}^{n} \epsilon_i^2)$.\
\
We know $\pmb H = \pmb X(\pmb X^\mathsf{T}\pmb X)^{-1}\pmb X^\mathsf{T}$,
$$
\begin{split}
E[Q(\hat{\pmb\beta})]&= tr((\pmb I_n-\pmb H)(\sigma^{2}\pmb I))+(\pmb X \pmb  \beta)^\mathsf{T}(\pmb I-\pmb H)(\pmb X \pmb  \beta)\\
&=\sigma^{2}tr((\pmb I_n-\pmb H)+\pmb \beta^\mathsf{T} (\pmb X^\mathsf{T}\pmb X-\pmb X^\mathsf{T}\pmb X)\pmb  \beta\\
&=\sigma^{2}tr((\pmb I_n-\pmb H)\\
&= \sigma^{2}{tr(\pmb I_n)-tr(\pmb H)}
\end{split}
$$
Since $\pmb H^{2} =\pmb X(\pmb X^\mathsf{T}\pmb X)^{-1}\pmb X^\mathsf{T}=\pmb H$ and $\pmb H$
is idempotent, 
$$
\begin{split}
tr(\pmb H)&= tr((\pmb X(\pmb X^\mathsf{T}\pmb X)^{-1}\pmb X^\mathsf{T}))\\
&= tr(\pmb X^\mathsf{T}\pmb X(\pmb X^\mathsf{T}\pmb X)^{-1})\\
&= tr(I_{p+1})\\
&= p+1
\end{split}
$$
so we can have,
$$
\begin{split}
E(\sum_{i=1}^{n} \epsilon_i^2 )&= E[Q(\hat{\pmb\beta})]\\
&= \sigma^{2}(n-(p+1))\\
&= \sigma^{2}(n-p-1)
\end{split}
$$
Therefore, 
$$
\begin{split}
E(\hat{\sigma}^2)&=\frac{1}{n-p-1} E(\sum_{i=1}^{n} \epsilon_i^2)\\
&=\sigma^{2}
\end{split}
$$
Hence, $\hat\sigma^2$ is an unbiased estimator of $\sigma^2$.\
\
For the $V(\hat\sigma^2)$:
$$
\begin{split}
V(\hat\sigma^2)&= V(\frac{SSR}{\sigma^2})\\
&= \frac{\sigma^4}{(n-p^*)^2}2(n-p^*)\\
&= \frac{2\sigma^4}{n-p^*}
\end{split}
$$

